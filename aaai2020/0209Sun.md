##  Document Analysis and Understanding

Liao et al. [Real-time scene text detection with differentiable binarization](http://aaai.org/Papers/AAAI/2020GB/AAAI-LiaoM.578.pdf)

- Task: read text in scene images (scene text detection)
- Approach: Differentiable Binarization. Compute segmentation map and threshold map, then convert to binarization map to get detection results.
- Experiment on five benchmark datasets of scene text. 
- Also compared speed of experiments.

Qiao et al., [Text perception: towards end-to-end arbitrary-shaped text spotting](http://aaai.org/Papers/AAAI/2020GB/AAAI-QiaoL.893.pdf)

- Task: scene text detection.

- Proposed a Shape Transformation Module

Hu et al., [GTC: Guided Training of CTC towards efficient and accurate scene text recognition](http://aaai.org/Papers/AAAI/2020GB/AAAI-HuW.7838.pdf)

- Scene text detection
- Approach:
  - Guided training: GCN+CTC Decoder
  - Inference: Only keep the GCN stream.



## Interpretable AI

Delleiger and Vreeken, [Explainable Data Decompositions](http://aaai.org/Papers/AAAI/2020GB/AAAI-DalleigerS.8171.pdf)

- Define the *pattern composition* problem with a regularized max likelihood.

  - $$
    l(\pi, S, A) = -\Sigma_{D_j} log p(D_j | S_j) + r(\pi, S, A)
    $$

  - D is a set of data points. S is the set of patterns.

- Fast method for discovering pattern components & compositions.

Zhang, [Systematically Exploring Associations among multivariate data](http://aaai.org/Papers/AAAI/2020GB/AAAI-ZhangL.1830.pdf)

- Propose the nCor: neighbor correlation coefficient
- Measure the local continuity of the reordered data points to quantify the strength of the global association between variables.

Qi et al., [Visualizing deep networks by optimizing with integrated gradients](http://aaai.org/Papers/AAAI/2020GB/AAAI-QiZ.4029.pdf)

- Propose I-GOS: optimizes for a heatmap, so that the classification scores on the masked image would maximally decrease.
- Train on integrated gradients instead of individual gradients, so it's less likely to get trapped in local minima.

Zhong et al., [Iteratively questioning and answering for interpretable legal judgment prediction](http://aaai.org/Papers/AAAI/2020GB/AAAI-ZhongH.7101.pdf)

- Network design:
  - Question Net: select questions from a given set
  - Answer Net: answer the question according to the fact description.
  - Predict Net: produce judgment results based on the answers.
- Design reward functions to minimize the n. questions asked.

Tomsett et al., [Sanity checks for saliency metrics](http://aaai.org/Papers/AAAI/2020GB/AAAI-TomsettR.8794.pdf)

- Investigate the properties of different approaches for measuring the fidelity of saliency map explanations for image classifiers.
- Propose a corresponding set of sanity checks for saliency metrics based on measures of reliability from psychometric testing literature.
- Psychometric test reliability is usually estimated in four separate ways (Peter 1979). Neural network as the agent, saliency methods as a battery of psychometric tests.
  - Inter-rater reliability: For each image, check the agreement of saliency metric scores.
  - Inter-method reliability: Assesses the degree to which test scores are consistent when there is a variation in the methods / instruments used.
  - Internal consistency reliability: Degree to which different methods intending to measure the same concept produce similar scores.
  - Test-retest reliability. (not relevant for saliency methods)

Virani et al., [Justification-based reliability in ML](http://aaai.org/Papers/AAAI/2020GB/AAAI-ViraniN.9085.pdf)

- Extend the Justified True Belief in epistemology, to characterizing the validity and limits of knowledge in supervised classifiers.
- An epistemic classifier characterizes the region where it is confident and not. The goal is to train an epistemic classifier.
  - JTB theory: knowledge = "justified + true" belief.
  - "justified": gathers evidence using the training set for each individual test input x in the layers of NN classifier, where:
    - an unambiguous truth state in the neighborhood of x in embedded spaces provide support to the belief 
  - allowing the model to declare "I know it", "I might know", or "I don't know" (output classification results from either "IK", "IMK" or "IDK").



## NLP session

Jin et al., [Is BERT really robust? A strong baseline for natural language attack on text classification and entailment](http://aaai.org/Papers/AAAI/2020GB/AAAI-JinD.7014.pdf)

- Adversarial perturbation approach:
  - Identify the important words
  - Change the words to the most semantically similar and grammatically correct words until the prediction is altered.

Sahin and Gurevych, [Investigating invertible NNs for inverse problems in morphology](http://aaai.org/Papers/AAAI/2020GB/AAAI-SahinG.7400.pdf) 

- Task: morphological inflection and lemmatization
- Use Invertible Neural Networks to optimize both direction problems simultaneously

Aguilar et al., [Knowledge Distillation from internal representations](http://aaai.org/Papers/AAAI/2020GB/AAAI-AguilarG.8219.pdf) 

- Distill the BERT representations into a simplified BERT version (with less layers).



## ML: Neural Nets etc. 

Tian et al., [Network as regularization for training DNN](http://aaai.org/Papers/AAAI/2020GB/AAAI-TianK.8084.pdf) 

- Propose Network as Regularization (NaR) - use an auxiliary network to dynamically incorporate guided semantic disturbance to the labels.
- Target-based regularization: instead of focusing on the primary class, the model also pays some attention to the other classes. Many existing regularization methods adopt prior knowledge as reg term in loss function.
- How is the auxiliary network trained? ground-truth label y, independently.
- Convex comb the two network's outputs as noise, then add this noise to label of training the target network.
- Good results on some datasets in comparison to baselines. 

Davel et al., [DNNs as layers of cooperating classifiers](http://aaai.org/Papers/AAAI/2020GB/AAAI-DavelM.8198.pdf)

- TODO - print and read this paper. Can't understand now.



## ML: Causal Learning and Bayes Nets

Faury et al., [Distributionally robust counterfactual risk minimization](http://aaai.org/Papers/AAAI/2020GB/AAAI-FauryL.3429.pdf)

- A unified framework for counterfactual risk minimization based on the DRO (distribuionally robust optimization) of policies.

Schwab et al., [Learning counterfactual Representations for Estimating Individual Dose-Response Curves](http://aaai.org/Papers/AAAI/2020GB/AAAI-SchwabP.4296.pdf)

- Dose Response Network (DRNet) architecture. Lower layers are shared, but higher layers branch into different heads.  Assign heads corresponding to the dosage strata.

Dhir and Lee, [Integrating Overlapping Datasets using Bivariate Causal Discovery](http://aaai.org/Papers/AAAI/2020GB/AAAI-DhirA.5855.pdf)

- Problem setting (motivating example). E.g., Dataset (X,Y) and (Y,Z) are separately collected. We know X->Y, and Y<->Z. Want to find if there are common causes between X and Z. But these two datasets are not measured at the same conditions. Need some *bivariate causal discovery* methods.
- Propose approach that outperform previous bivariate causal discovery algorithms.

Yu et al., [A new framework for online testing of heterogeneous treatment effect](http://aaai.org/Papers/AAAI/2020GB/AAAI-YuM.6025.pdf)

- Propose Sequential Score Test (SST)
  - Can control type I error under continuous monitoring and detect multi-dimensional heterogeneous treatment effects.
- Compare to SOTA online test (mSPRT).



## ML: Fairness and Privacy, Learning Theory

Davidson and Ravi., [Making existing clusterings fairer: algos, complexity results, and insights](http://aaai.org/Papers/AAAI/2020GB/AAAI-DavidsonI.5319.pdf)

- Formulate the minimal cluster modification for fairness (MCMF) problem.
  - Input: a given partitional clustering
  - Goal: minimally change it, so that the clustering is still of good quality and fairer.

Dutta et al., [An info-theoretic quantification of discrimination with Exempt Features](http://aaai.org/Papers/AAAI/2020GB/AAAI-DuttaS.9451.pdf)

- Goal: define non-exempt discrimination, while exempting discrimination due to critical features.
- Tool: partial information decomposition (PID) from information theory
  - Counterfactual causal influence & counterfactual fairness
- Decomposition of total discrimination into four non-negative components (exempt and non-exempt visible discrimination, exempt and non-exempt masked discrimination)
- An impossibility result (no purely observational measure of non-exempt discrimination can satisfy all our desirable properties)
- Observational relaxations

Harder et al., [Interpretable and differentially private predictions](http://aaai.org/Papers/AAAI/2020GB/AAAI-HarderF.3435.pdf)

- Trade-off between interpretability, privacy, and accuracy.
- Propose a family of interpretable models ("LLM, locally linear maps"), accounting privacy and interpretability.
- Provide DP "local" and "global" explanations on classification.
- Use random projections (Johnson-Lindenstrauss transform) to better deal with privacy and accuracy trade-off.

Wang and Zhou, [Differentially private learning with small public data](http://aaai.org/Papers/AAAI/2020GB/AAAI-WangJ.9491.pdf)

- Private-public stochastic gradient descent.
- Use public database to adjust privacy budget & gradient clipping of SGD training of private training database. Also use public database to fine-tune the model.