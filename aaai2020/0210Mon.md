## Games: Description Languages and NLP

(Madison, 930-1045)

Goldwaser and Thielscher, [Deep RL for general game playing](https://aaai.org/Papers/AAAI/2020GB/AAAI-GoldwaserA.4814.pdf) 

- General Game Playing: providing game rules only at runtime. Agents are allowed some starttime to analyze the game strategies.
- Game Description Language (GDL) logical programming
  - Previous approaches: Construct propositional networks
- Proposed approach: GCP with reinforcement learning
- Limitations for AlphaZero: Needs a handcrafted neural network, zero sum, turn-based, two-player, play-specific. How to remove these limitations?
  - GDL input -> Propositional network->DNN->RL, computing expected reward for move probabilities of multiple players' outputs.
  - The DNN is shared (for common feature extraction)
  - Each player has their own move space. Move simultaneously.
  - Automatically generated NN
  - Expected reward allows cooperative strategies.
- Evaluation method:
  - Compared to UCT: run both with equal time per move, and run with equal number of simulations

Hayton et al., [Narrative Planning Model Acquisition from Text summaries and descriptions](https://aaai.org/Papers/AAAI/2020GB/AAAI-HaytonT.6762.pdf)

- Background: baseline narrative planning.
- Aim of this work: approach to assist authors / reduce authoring burden via a semi-automated route to baseline narrative planning model development.
- Planning model acquisition from text summaries
  - From input natural language sentences to baseline domain model
  - Segmentation -> Object identification -> Reference co-resolution -> Narrative domain model acquisition (target PDDL representation)
  - Domain model acquisition: the output is a PDDL model (Planning domain definition language. McDermott et al., 1998)

Hausknecht et al., [Interactive Fiction Games: A Colossal Adventure](https://aaai.org/Papers/AAAI/2020GB/AAAI-HausknechtM.9405.pdf) 

- Interactive Fiction games are fully text-based simulation environments where a player issues text commands to effect change in the environment and progress through the story.
- Challenges IF games provide for agents:
  - Combinational Action Space
  - Commonsense Reasoning
  - Knowledge Representation
- Introduce Jericho: learning environment for 56 man-made IF games across the spectrum of difficulty.
  - Reward / game over / victory detection
  - Save / load game states
  - Walkthroughs, vocabulary identification, action templates, valid action detection...

Shi et al,. [Fast and Robust Face-to-Parameter Translation for Game character auto-creation](https://aaai.org/Papers/AAAI/2020GB/AAAI-ShiT.147.pdf) 

- Formulate a "game character auto-creation" framework": predict a large set of physically meaningful facial parameters under a self-supervised learning paradigm, according to the input face photo.
- Previous methods: 
  - 3D reconstruction (morphable face models of 3D reconstructions vs. bone-driven face models in RPG games)
  - F2P (face to parameters): iteratively adjust params at the input end of the renderer by gradient descent. Slow.
- Propose network:
  - Translator T and Imitator G. Optimize using a cycle-consistency loss.
  - Also has segmentation networks, etc. See orig paper for their pipeline.
- Evaluation:
  - Two games: Justice and Revelation.
  - Subjective evaluation from 15 volunteers.
  - Ablation studies on several loss components.

Liu et al., [A Character-centric neural model for automated story generation](https://aaai.org/Papers/AAAI/2020GB/AAAI-LiuD. 6731.pdf) 

- Task: Automated story generation.
- Previous models (VAE, GAN, Conv-Seq2Seq) models didn't incorporate attributes and prior knowledge of the story genre.
- Proposed method: combine deep generation networks with character modeling (allocate a consistent character to a story, via encoding it into the distributed embedding)
- Decompose the story generation into two steps:
  - First, determine the character's reaction to the current situation at each time step
  - Second, generate a complete sentence by incorporating the character embedding, predicted action, and the situation information.
- Experiment:
  - Dataset: corpus of movie plot summaries extracted from Wikipedia
  - Baseline models: Conditional LM, S2S with attention, incremental S2S with attention, plan-and-write, event representation, hierarchical convolution sequence model.
  - Evaluation metrics: BLEU, Perplexity, Human Evaluation.

Fan et al., [Generating Interactive Worlds with Text](https://aaai.org/Papers/AAAI/2020GB/AAAI-FanA.7370.pdf) 

- Task: generate cohesive and interesting game environments.
- Investigate a ML approach for world creating, using the LIGHT game environment.
- Use NN-based models to compositionally arrange locations, characters, and objects into a coherent whole.

Yu et al., [Draft and Edit: Automatic storytelling through multi-pass hierarchical conditional VAE](https://aaai.org/Papers/AAAI/2020GB/AAAI-YuM.8133.pdf) 

- Main challenge of story generation: 
  - Consistency
    - Current SOTA solution: exploit intermediate representations (keywords, events, skeleton) to provide better guidance for the story generation process. Risky + Complex
  - Diversity
    - VAE with noise (also has drawbacks and randomness)
- Propose model
  - Consistency: use hierarchical structure
  - Diversity: CVAE model + Multi-pass generation.



## Application: Human Modeling

(Beekman, 1115-1230)

Zhang et al., [Variational Pathway Reasoning for EEG emotion recognition](https://aaai.org/Papers/AAAI/2020GB/AAAI-ZhangT.2962.pdf) 

- Introduced Variational Pathway Reasoning (VPR) method to EEG emotion recognition.
- A salient pathway reasoning method is proposed:
  - EEG -> {Random walk -> pathway candidates -> Sequence modeling -> Pathway codes} (pathway sampling and coding) -> Salient pathway reasoning
  - How to do salient pathway reasoning? Sparse variation scaling, pseudo salient pathways, etc.... -> Full conv layer
- Experiments:
  - Accuracy vs benchmarks
  - Visualization of salient pathways.

Mittal et al., [M3ER: Multiplicative MultiModal Emotion recognition using facial, textual, and speech cues](https://aaai.org/Papers/AAAI/2020GB/AAAI-MittalT.4411.pdf) 

- Task: emotion perception
  - Input: image, speech, etc. Output: perceived emotion.
- Previous approaches:
  - Unimodal emotion recognition. Either of facial, speech, body gestures, or physiological features.
  - Multimodal emotion recognition. Early fusion, dynamic fusion graphs, tensor fusion networks, etc.
- Approach: M3ER
  - Modality check step with CCA. Discard some ineffective modalities with some heuristics.
  - Proxy feature generator. Generate proxy feature vectors for the ineffectual modalities using a linear transformation.
  - Multiplicative combination step.
- Dataset:
  - IEMOCAP Dataset (Busso et al., 2008). 3 modalities of 10 actors.
  - CMU MOSEI dataset (Zadeh et al., 2018)

Zhao et al., [An end-to-end visual-audio attention network for emotion recognition in user-generated videos](https://aaai.org/Papers/AAAI/2020GB/AAAI-ZhaoS.7155.pdf) 

- Challenges in emotion recognition:
  - Large intra-class ariation: affective gap
  - Low structured consistency: resolutions and bulrring noises
  - Sparse keyframe expression. Only limited keyframes directly convey and determine emotions.
- Propose visual-audio attention network (VAANet), to study emotion recognition task in user-generated video in E2E manner.
- Polarity-consistent cross entorpy loss (increase the penalty coefficient if the polarity of prediction is different from the ground truth label).

Song et al., [Instance-Adaptive graph for EEG emotion recognition](https://aaai.org/Papers/AAAI/2020GB/AAAI-SongT.2747.pdf) 

- Propose Instance-adaptive graph
- (See Figure 2)  Use instance -adaptive branch to achieve the dynamic graphic connections.
- Then process EEG by multi-level and multi-graph convolution, graph coarsening, region dependency modeling, then FC and softmax.

Bhattacharya et al., [STEP: Spatial Temporal Graph Convolutional Networks for emotion perception from gaits](https://aaai.org/Papers/AAAI/2020GB/AAAI-BhattacharyaU.2895.pdf) 

- Use real+generated data and gait-based effective features.
- Generate with conditional VAE.
- Use novel emotion-gait dataset.

Perrault et al., [End-to-end game-focused learning of adversary behavior in security games](https://aaai.org/Papers/AAAI/2020GB/AAAI-PerraultA.5897.pdf) 

- Problem: want to generalize from one security game to another against the same adversary
  - Adversary has a fixed but unobserved attractiveness function
  - Goal: learn the attractiveness function to maximize defender utility.
- Using a predict then optimize approach may not maximize utility
- This paper: learn a predictive model using a game-focused loss function
  - Maximize a surrogate for decision quality.
- Result: better performance with less data.

Yang et al., [Instance-wise dynamic sensor selection for human activity recognition](https://aaai.org/Papers/AAAI/2020GB/AAAI-YangX.7952.pdf)

- Need more sensors to recognize human activies, but how to balance sensoe numbers and the cost?
- Alternatively minimize classification loss and sensor number
  - MDP-based sensor model, sensoe-adaptive activity model, Mutual DAgger imitation learning.

## ML Unsupervised and Semi-supervised Learning, clustering 2

(TODO - read their papers)

Chen et al., [Multi-view clustering in latent embedding space](https://aaai.org/Papers/AAAI/2020GB/AAAI-ChenM.5090.pdf) 

- Background: global similarity learning
- Learn a similarity matrix S, where s_ij is the similarity between sample i and j
- Propose MCLES approach: optimize Eq (9).
- Evaluate on ACC, NMI, and PUR against various baselines.

Chen and Batmanghelich, [Weakly supervised disentanglement by pairwise similarities](https://aaai.org/Papers/AAAI/2020GB/AAAI-ChenJ.1491.pdf) 

- TODO

Tang et al., [Label enhancement with sample correlations via low-rank representation](https://aaai.org/Papers/AAAI/2020GB/AAAI-TangH.3134.pdf) 

- TODO

Yin et al., [Shared Generative Latent Representation learning for multi-view clustering](https://aaai.org/Papers/AAAI/2020GB/AAAI-YinM-3751.pdf) 

- TODO

He et al., [Heterogeneous transfer learning with weighted instance-correspondence data](https://aaai.org/Papers/AAAI/2020GB/AAAI-HeY.7460.pdf) 

- TODO

## ML Unsupervised and semi-supervised learning, clustering 3

(Concourse A, 1400-1515)

Zhou et al., [Multi-view spectral clustering with optimal neighborhood laplacian matrix](https://aaai.org/Papers/AAAI/2020GB/AAAI-ZhouS.4849.pdf) 

- The current linear combination-based multi-view spectral clustering framework could: (1) limit the representation capacity of the learned Laplacian matrix, and (2) insufficiently explore the high-order neighborhood information among data
- Provide a flexible optimal Laplacian matrix construction mechanism to solve the aforementioned issues.
  - Seeds an optimal Laplacian matrix L* in the neighborhood of both the linear comb of first-order and high-order base Laplacian matrices.
- Experimental study on eight benchmark datasets.

Sun et al., [Lifelong spectral clustering](https://aaai.org/Papers/AAAI/2020GB/AAAI-SunG.2320.pdf) 

- Spectral clustering in lifelong learning setting
- Two common knowledge libraries: orthogonal basis library B and feature embedding library F.

Wang et al., [Robust self-weighted multi-view projection clustering](https://aaai.org/Papers/AAAI/2020GB/AAAI-WangB.4495.pdf) 

- Propose RSwMPC. 
- Subspace learning is performed by adding a projection matrix. Feature selection and noise suppression are achieved by introducing the l_2,1-norm penalty term of the projection matrix.
- Parameter-free self-weighted strategy.
- Experiments on synthetic and real-world datasets.

Ma et al., [Inefficiency of K-FAC for large batch size training](https://aaai.org/Papers/AAAI/2020GB/AAAI-MaL.6294.pdf)

- Can second order method (K-FAC) improve the critical batch size problems? 
- K-FAC also significantly deviate from ideal strong scaling behaviour, when training beyond a critical batch size.
- Experiments on CIFAR-10 and SVHN.

Cheng et al., [Outlier detection ensemble with embedded feature selection](https://aaai.org/Papers/AAAI/2020GB/AAAI-ChengL.6641.pdf) 

- Motivation: outlier detection. feature selection. Usually these two steps are done separately or iteratively.
- Solution: ODEFS: Integration of feature selection, outlier candidates selection, and outlier detection.

[Deep Embedded Non-redundant clustering](https://aaai.org/Papers/AAAI/2020GB/AAAI-MiklautzL.7182.pdf)

- What is non-redundant clustering? 
- Deep clustering techniques cluster in the latent space.
- Joint learn the class-specific clusters of representations in latent space using a non-redundant clustering layer.

Li et al., [IVFS: Simple adn efficient feature selection for high-dimensional topology preservation](https://aaai.org/Papers/AAAI/2020GB/AAAI-LiX.9315.pdf) 

- IVFS is inspired by random subset method.
- Proposed algorithm can provide satisfactory performance under a sharp sub-sampling rate.

Guo et al., [Preserving ordinal consensus: towards feature selection for unlabeled data](https://aaai.org/Papers/AAAI/2020GB/AAAI-GuoJ.9616.pdf)  

- Motivation: 
  - exploit one-to-one correspondence
  - exploit feature-level ordinal information
- Method: self-paced joint learning model

## ML Domain Adaptation, *-Learning.

(Murray Hill, 1545-1715)

Lee et al., [Residual Continual Learning](https://aaai.org/Papers/AAAI/2020GB/AAAI-LeeJ.4101.pdf) 

- What is continual learning? Learn multiple tasks sequentially, without forgetting.
- Linear combination of source network and target network, to form a combined network.

Chandak et al., [Lifelong Learning with a changing action set](https://aaai.org/Papers/AAAI/2020GB/AAAI-ChandakY.6189.pdf) 

- (Outstanding student paper award, honorable mention)
- Lifelong MDP setup:
  - How do we capture the notion of underlying structure in action space?
  - How does the action set change?
  - What are the characteristic properties of a changing action set?
- Proposed solution:
  - A policy parameterization that is invariant to the cardinality of the action set.
  - A new obj func which can be used to update the agent when new actions are introduced.
- Proposed method:
  - What if we could infer the underlying structure in the action space and whenever a new action is introduced we associate its behavior using the inferred underlying structure?
  - Policy parameterization is critical.

Li et al., [Learning transferable adversarial examples via ghost networks](https://aaai.org/Papers/AAAI/2020GB/AAAI-LiY.443.pdf) 

- Longitudinally ensemble the ghost networks.
- Dropout erosion; skip connection erosion
- Evaluate on the NeurIPS 2017 adversarial challenge.

Liu et al., [Attribute propagation network for graph zero-shot learning](https://aaai.org/Papers/AAAI/2020GB/AAAI-LiuL.1273.pdf) 

- Aim to optimize the attribute space in the context of ZSL, and leverage the inter-class relations to generate more powerful attribute vector per class.
- APNet: propagate the attributes of every class on the category graph to its neighbors in order to generate attribute vectors.
- Inspired by belief propagation, message passing and label propagation. Also related to GNN.

Zhu and Li, [Semi-supervised streaming learning with emerging new labels](https://aaai.org/Papers/AAAI/2020GB/AAAI-ZhuY.4960.pdf) 

- Problem: the data are collected in the stream. New class hides in unlabeled data.
- Solution: semi-supervised learning framework "SEEN" method:
  - Add the data point to a buffer, if it is likely belonging to a new class. (as determined by a detector)
  - How to add the data points from the buffer into corresponding category, if a new label is introduced?
  - SeenLP for known class classification, usign label propagation.



## Debate: Academic AI Research in an Age of Industry Labs

(Grand Ballroom, 1815-1915)

