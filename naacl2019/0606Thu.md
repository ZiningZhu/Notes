# 0606 Thu SemEval and *SEM  

## Task-independent NLU models
(9:30-10:30, Sam Bowman, Great Lakes A)  

A general-purpose sentence encoder tries to encode the semantics in the reusable network components.  
- The upper layer can be trained with relatively small task-specific data -> "What do the labels in this task mean?"  
- Case study: ELMO  

The GLUE language understanding benchmark  
- General Language Understanding Evaluation
- 9 tasks as diverse as possible: WNLI, RTE, MRPC, STS-B, CoLA, SST-2, CoLA, QQP, QNLI 
- All sentence (or sentence pairs) classification

The successes with unsupervised pretraining and fine-tuning on GLUE


The updated SuperGLUE benchmark
- [paper](https://w4ngatang.github.io/static/papers/superglue.pdf)
- The downloading scripts, etc. are accessible through the [Jiant toolkit](https://github.com/nyu-mll/jiant)

Easy transfer learning with STILTs  

A few more thing we've learnt with these models  
- Nothing works significantly better than language modeling  
- Pre-training helps.
- The correlations between these tasks are low. The models tend to be task-specific.
- Another view: edge probing. To what extent are ELMo and BERT already doing syntactic / semantic tasks? (ICLR 2019)


## Task 1-3 presentations
(10:30-12:30 )  

Task 1: Cross-lingual semantic parsing with UCCA  

Task 2: Unsupervised lexical frame induction  
- Task A: identifying semantic frames
- Task B.1 "full" frame semantic tagging (WordNet roles)
- Task B.2 Case role labeling (VerbNet roles)  
- Dataset: WSJ corpus (PTB) 3 annotators

## Task 5-6 presentations 
(14:00-15:00)  

Task 5: Hate speech detection

Task 6: Offensive speech detection


## Poster
(15:00-15:45 Exhibit Hall)  

## DISRPT session
(16:00-17:30 Nicollet D3)  

Towards discourse annotation and sentiment analysis of the Basque Opinion Corpus  
- Basque opinion Corpus:
  - 240 opinion texts collected from different websites
  - Domains: sports, politiss, music, moves, etc.
- Methodology steps:
  - Set the stage for the annotating work
- Annotation procedure and process: (Das and Taboada, 2018). Follow a parse algorithm to build up a tree (leafe nodes are sentences).
- The structure reveal some information about the sentiments. e.g., "In CONCESSION relations,
the semantic orientation of the nucleus always prevails but the valence of the satellite must also be
taken into consideration. In EVALUATION relations, words with sentiment valence concentrate
on satellite."

Using rhetorical structure theory to assess discourse coherence for non-native spontaneous speech  
- Background: SpeechRater
- Goals:
  - Annotate spontaneous spoken corpus using RST
  - Develop an automatic RST parser
  - Derive discourse features from RST trees
  - Use RST-based features for non-native speech scoring
- Derive 8 features from RST theory

Applying rhetorical structure theory to student essays for providing automated writing feedback  
- RST: Rhetorical structure theory (a descriptive theory about the structures of the text)  
- Decide nuclearity flowchart
- Open sourced the annotation guideline & flowchart: http://tinyurl.com/RSTguideline

