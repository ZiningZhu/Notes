# 0603 Mon 

## Keynote: data as a mirror of society  
(Nicollet Ballroom)  
Statistical learning models show stereotypes.  
e.g., (Caliskan et al., Science 2017), etc.  
 - Implicit association tests  
 - Universal associations in word embeddings  

Propose two approaches:  
1. Deeper understanding of human culture can help identify possible harmful stereotypes in alg systems.  
 - Occupatioin vs. constituency parsing descrepancies
 - Racial bias in language indentification: AAE tweets are more likely to be classified as non-English.  
 - Is classifying some tweets as AAE a form of stereotyping? Or is that because the "English or not" training data contains mostly non-AAE?  
 - HireVue: Use accents, body languages, etc., for deciding on ideal candidates.  
 - WeSee: detect suspicious activity using data from sports, etc. E.g., to what degree is the person smiling or angry?   

2. If data is a mirror of society, then ML models could be used like a magnifying glass to help us understand human cultures.   
- Classifying words as gender specific or gender-neutral  
- Word embeddings quantify 100 years of gender bias. (PNAS 2018) 
- Does language merely reflect or also cause stereotypes? (What are we learning from language? PNAS 2019) Found association between bias and language usage in 25 lanugages.  


## 1A Cognitive  
(Nicollet B/C)  

Entity recognition at first sight: Improving NER with eye movement information  
- Hollenstein and Zhang  
- Psycholinguistic evidence of fixation.
- Concatenate the gaze embeddings (eye movement features) onto word embeddings.  
- Experiment on dataset:
  - Eye tracking: Dundee, GEGO, ZuCo
  

The emergence of number and syntax units in LSTM LMs  
(Lakretz et al)  
- Background: Subject-verb agreement (number agreement)   
- LSTM-LM information storage is controlled by the forget and input gates. But how do they track the long-distance number information?  
- Datasets and probing tasks:
  - Number-agreement task: (Linzen et al. 2016) and (Gulordava et al. 2018). Compare the log prob of the correct / incorrect verb occurring, given the context. There are drastic decrease in incorrect words.
  - Syntac units: The tree-depth dataset (Nelson et al, 2017). Inputting the hidden representations (from pretrained LSTM LM. Gulordava et al. 2018), predict the number of open syntactic nodes at each word (if given the canonical syntactic parse of a sentence).
- Visualizing gate and cell-state dynamics.
  - The singular and plural units emerged at the second layer of the network. 
  - Test whether subject number can be decoded (using a linear model) from the whole pattern of activities in the network, and whether this decoding is stable across time.
- Our analysis thus provides direct evidence for the claim that LSTMs trained on unannotated corpus data, despite lacking significant linguistic priors, learn to perform structure-dependent linguistic operations.

Neural Self-training through spaced repetition  
(Amiri)  
- Motivation: labeled data is expensive & time-consuming to obtain. -> Self-training and unsupervised pretraining.  
- Self-training: boostrapping.  
- Pre-training: layers are pre-trained by learning to reconstruct their inputs (autoencoder pre-training): the same neural model or parts should be used in both pretraining and fine-tuning steps. Decoupled this procedure.
- Neural self-training based on *Leitner Queues*, and a sampling policy learner.  
- Leitner queue updating: First place all unlabeled data in the first queue. Then move instances among queues based on network predictions: promote if correctly classified; demote if otherwise.   
- Harder / easier instances. Greedy data sampling approach. Select instances of the queue that most improves learner's performance on validation data (designated queue)  
- Evaluation on IMDB (subset, movie reviews) and Churn (user intention)  
- Model introspection:   
  - Q1: What's the issue with Highest Queues? Look at cosine similarity between representations of training instances queue instances.  
  - Q2: Does sample diversity matter? Compute the extent of diversity that each given queue introduces when added t o training data.   
  - Q3: Do we need better sampling policies? Analyze the instance movement patterns among queues.  
- Conclusion: novel data sampling approach based on Leitner Queues.  

Neural LMs as psycho-linguistic subjects: representations of syntactic state  
(Futrell et al)  
- Question: what are the actual information encoded in blacbox model hidden representations? -> Do psycholinguistics on neural network models.  
- NNLM tested: JRNN (Jozefowicz et al, 2016), GRNN (Gulordava et al, 2018), RNNG (Dyer et al, 2016), TinyLSTM. 
- Method: design sentences such that NN surprisals reveal representation of syntactic states. Imiporting methods and analytical tecns from the field of human sentence processing in psycholinguistics. Study a number of kinds of syntactic state, and ask:  
  1. Do NN LMs represent the state?
  2. What cues do NNs use to infer the onset of the state?    
- Subordinate clauses.  
- Syntactic state. "Garden paths effect".   

Understanding language-elicited EEG data by predicting it from a fine-tuned LM
- Dan Schwartz and Tom Mitchell  
- Different modalities of word meaning are stored in different areas in brains. Also another brain component integrates these meaning modalities.  
- ERP (Event-related potentials)    


## Careers in NLP panel  
(Nicollet Ballroom, 1-2:30pm)  
- Speakers:  
  - Phillip Rasnik  
  - Judith Klavans
  - Yunyao Li
  - Owen Rambow
  - Joel Tetreault  

Some topics I remember:  
**Leadership** 
- Being an individual contributor or a team manager? Leadership is not about titles. Should relate yourselves to the rest of the community.  
- Managing is different from leading. Management is not mentioned much in universities.  
- Podcast: "Coaching for leaders", "Leaders are not born; they are made". You observe. You don't complain; but instead come up with solutions.  
- Can develop skills in grad schools. E.g., You have good ideas, but how do you deliver? How do you define projects? How do you deliver?  
- Leadership is about vision and creating vision.  
- You really need to learn to listen. In grad schools we don't listen. Should make people feel they are listened to.  

**Time management**  
- How much of the non-academic things are you doing, in either academic or non-academic lives? "In Columbia, I ended up spending all time doing non-research stuffs. ... doing spreadsheets, talking to people, etc." How much time spent on emails / slack? -> Rather over-communicate.  
- Count reading group as "meeting time" or "doing research"? How about coding? -> coding is definitely counted as doing research.

**Career choice**  
- Most NLP people here does not only use blackbox NLP tools.  
- Places hire you for (1) who you are, and (2) who you are going to become. 
- Does domain expertise matter?  

**Networking**  
- Don't even need to ask them to invest in a coffee time. Just need to start the conversation (or just join in random conversations. It's totally cool.)  
- Ideas. Are you concerned when you give them your ideas? IP issues w.r.t companies (especially startups)? IBM research has a collaboration structure supporting researches in univ and students.   

**Organizational**  
- How much control do junior students in your groups have? IBM example: identify projects this person can be productive. Either leverage the student's skills, or let them develop.    
- Everybody has more than one projects in IBM. Product / research projects are involved.  
- Look at the micro-context. Identify: who are evaluating your works? Who are deciding the directions of works? What are they thinking? Incentives? (e.g., IP) 

**Work / life balances** 
- One reason to stay in IBM is work/life balance. Giant companies have flexibility of publication directions.  
- Small companies: your research goals align highly with them.  

**Researches in industry**  
- Also government and non-profits.  
- Non-profits love IPs. Govs do not. Research institutes vary...?  
- Transition from e.g., post-doc into industry.  
- Encourage everyone to try at least one industry internships. At least know where do the problems come from. Connect to other people.  


## 2A Dialogue & Discourse
(Northstar A)  

IMHO Fine-tuning improves claim detection  
- Charkrabarty and Hidey  
- Existing argumentation datasets: 
  - Monologue: Microtext (MT), Persuasive Essay (PE)
  - Dialogue: Web discourse (WD), Change My View (CMV)  
  - They are small and imbalance.
- Difference in phrasing across datasets:
  - MT: 50% of claim sentences contain the modal verb 'should'. PE: propositional verbs. etc.,
- Collect 5.5 Million sentences containing "IMHO" marker. These are self-labeled claims.
- Transfer learning. Three steps of ULMFit:
  - LM on general domain
  - Task-specific fine-tune the LM, on IMHO dataset
  - Then train/test classifiers.
- Potential model bias? e.g., some premises are mis-classified as claims.  

Joint Multiple intent detection and slot labeling for goal-oriented dialog  
- Gangaharaiah and Narayanaswamy  
- Identify the intent (sentence classification task) and slot label (sequential labeling problem)  
- Intents are predicted both at the sentence level and at the token level. The predictions use LSTM.
- Datasets: ATIS, SNIPS  

CITE: A corpus of image-text discourse relations  
- Existing datasets: TODO  
- This is the first dataset describing discourse relations across text and imagery
- This dataset can be used to train classifiers to support automated discourse analysis
- Dataset is on [Github](http://github.com/malihealikhani/CITE)


## 3F Applications, social media, biomedical NLP 
(Hyatt Exhibit Hall)  

Detecting cognitive impairments by agreeing on interpretations of linguistic features  
(Our poster)  
- Groups of linguistic features contain important common informations.  
- In a biomedical scenario (i.e., DementiaBank with around 500 data points and 413 linguistic features), using Consensus Networks could reach higher accuracies than traditional classifiers.
![My poster](https://res.cloudinary.com/dnijsrvoc/image/upload/v1560093706/Blog/2019_naacl/0603poster_CN_jikfeu.jpg)


Fairseq: a fast, extensible toolkit for sequence modeling  
- Open-source, PyTorch-based  
- Allows developers to train custom models for translation, summarization, LM, and other text generation tasks.
