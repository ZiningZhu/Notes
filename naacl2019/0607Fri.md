# 0607 Fri  

## Morning talk at ClinicalNLP
**Enhancing quality and robustness of biomedical information extraction**  
(9:15-10:30 Nicollet D1)  

Problem: there are too much data and too little time.  
Overall goal: build knowledge network to accelerate scientific discovery  

Background: entity extraction and linking
- Abstract meaning representation for mentions
- Entity linking to 300+ biomedical ontologies. E.g., document-level co-occurrence graphs
- Aiming for higher quality: supervised approach to entity extraction. e.g., CRF+LSTM

Moving from biomedical literature to clinical notes: informal and contains many ambiguous abbreviations
- Supervised models are very fragile: moving from formal genre to informal genre.
- Solution: make supervised models more robust.
- Context-aware relation extraction. e.g., using GCN etc.

AMR-based unsupervised event extraction

Application in speeding up scientific discovery
- Create new ideas
- Write a new paper about the new ideas (e.g., PaperRobot in ACL 2019). Predict links between nodes -> follow the templates -> generate incremental paper  
  - Link prediction on top of IE
  - Repetition removal: Use a coverage loss to avoid any entity in reference input text or related entity receiving attention multiple times
- PaperRobot could help researchers generate drafts. Some profs translate students' PPTs into paper drafts -> could relieve this work.
- This approach does not work for NLP yet. Don't have enough data.

Discussion about evaluation metrics in NLP
- If e.g., the accuracy reaches 90% we should probably stop working on it and shift to other datasets. 2 percent of accuracy might not mean a lot. More scenarios should be explored.  

## Presentation session 1
(11:20 - 12:30 Nicollet D1)  

Effective feature representation for clinical text concept extraction (Tao et al)  
- Background: crucial information of healthcare recorded only in free-form text.
- Datasets:
  - Scientific: pubmed
  - CLinical: diagnosis detection prescription reasons
  - Social: penn adverse drug reactions
  - Commercial: drug-Disease relations
  - chemical-disease relations
  - Problem: the size of dataset is small
- Task: clinical text annotation
  - Diagnosis detection: positive symptoms / concern
  - Predcription reasons: prescribed drug; and reason
  - Penn Adverse drug reactions: "ADR"
  - etc...
- Previous methods:
  - LSTM-CRF: general text
  - HB-CRF: applied to clinical text. Gathered sparse hand-built features.
- Propose combined model:
  - ELMo-LSTM-CRF-HB. Dense ELMo word embeddings + sparse hand-built features.
- Evaluation: per-token macro-F1 scores
- Baselines:
  - rand-LSTM-CRF (randomly initialized word embeddings + LSTM)
  - HB-CRF
  - ELMo+CRF
  - etc.
- Experiments:
  - The role of text length. LSTM handles short texts well. HB-CRF is however robust on long texts.
  - Inspect the CRF potential scores. See which features are more important. -> LSTM features are always more important; HB features make substantial contribution as well.
  - The major improvements of proposed models come from minor categories.

An analysis of attention over clinical notes for predictive tasks  (Jain et al)  
- How to encode clinical text? Desiderata:
  - Predictive performance
  - Transparency
  - Correct causal modeling
- Tasks and datasets:
  - MIMIC III: three tasks of it
  - Surgical notes for hip / knee arthroplasty: predict 30 day re-admission
- Evaluation: predictive performance.
- Models: Logistic regression, BiLSTM, Bi-LSTM with attention (either softmax or logodds as attentions -> logodds are better at both train and test).  
- Transparency: attention is explanation (e.g., weights of importance) or not?
- Causal modeling: counterfactual experiment. Attention permutation experiment.
- Takeaway:
  - LogReg provides competitive baseline
  - Hidden state aggregation using attention or max pool are important for neural models
  - Transparency could be a tradeoff in neural models
  - Attention does not solve transparency issues.


Extracting adverse drug event information with minimal engineering (Miller et al)  
- Background: adverse drug events from clinical notes
- Items for the Track 2 in 2018 n2c2 challenge
  - Drug and attribute extraction (NER)
  - Relation classification (gold entities)
  - Relation extraction (end2end)
- Goal:
  - pre-challenge: benchmark standard info extraction approaches
  - post-challenge: compare neural vs feature-based methods
  - general: build systems for ADE extraction
- Minimal engineering
- Traditional system: SVM-based relation system
- Neural methods: use FLAIR (because it's char-level and has easy-to-use API) as embedding, Use modified form of xml representation from Dligach et al (EACL 2017). 


Hierarchical nested NER
- Task: we want to detect entities within entities (NER within NER), especially those within medical texonomies
- Model: based on Yang et al (2015). Sequential model which transverses the input text and predicts and action per step.
- Dataset: word stack.
- At each step, the model predicts one of the four actions: (1) transition, (2) shift, (3) reduce ("ends the mention I started"), and (4) out (to ignore the word)


## Presentation session 2
(14:00 - 15:30 Nicollet D1)  

Towards automatic generation of shareable synthetic clinical notes using neural language models

A novel system for extractive clinical note summarization using EHR data  
- Extractive summarization for unstructured clinical notes.
- Baseline: SVM-linear, CRF (linear chain), CNN, Bi-LSTM-CRF.
- Proposed model: break down the problem into separate components.

A BERT-based universal model for both within- and cross-sentence clinical temporal relation extraction

Publicly available clinical BERT embeddings
- Compared BERT, BioBERT and BERT-MIMIC

## Poster session
(16:00-16:45 Exhibit Hall)  


## NLP vs structured data in the clinical domain
(16:45 - 17:30 panel discussion, Nicollet D1)  
